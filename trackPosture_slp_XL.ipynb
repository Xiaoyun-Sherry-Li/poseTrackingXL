{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:28:54.850697Z",
     "start_time": "2025-03-11T03:28:48.665235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/utils\")\n",
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/bird_pose_tracking/faceNet\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "''' set up for this run '''\n",
    "# set up GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "from tensorflow.keras.models import load_model as tf_load\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import faceNetArchitectures\n",
    "from load_matlab_data import loadmat_sbx\n",
    "from slp_utils_XL import posture_tracker, create_slp_project, crop_from_com\n",
    "import scipy.io"
   ],
   "id": "1ede65d5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:29:36.485486Z",
     "start_time": "2025-03-11T03:29:36.450674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' UPDATE data params as appropriate'''\n",
    "# cam params\n",
    "cam_ids = ['blue_cam', 'green_cam', 'red_cam', 'yellow_cam'] # check the input order\n",
    "im_w = 2200\n",
    "im_h = 650\n",
    "# video params\n",
    "start_frame = 0 # in frames at 50fps # (XL, 010825: an exampler coconut caching/eating + drinking water snippet: 11:50 - 13:00 min in SLV123_110824_wEphys) \n",
    "nFrames = 399276 # to extract entire video #90000 # in frames at 50fps # takes 0.5 hour = 1 * 30 * 60 * 50 \n",
    "\n",
    "''' UPDATE paths as needed '''\n",
    "# videos\n",
    "root_dir = \"Z:/Sherry/acquisition/\"\n",
    "vid_root = f\"{root_dir}AMB155_031025/\"\n",
    "# camera params\n",
    "cam_params = loadmat_sbx(\"Z:/Sherry/poseTrackingXL/calibration_files/all_opt_arrays/102324_negated_camParams\")['camParams_negateR'] #['camParams']\n",
    "\n",
    "# to save\n",
    "pred_date = \"031025\"\n",
    "save_file = f'{pred_date}_posture_face.npy' # python\n",
    "# save_file = f'{pred_date}_posture_2stage_faceNet.mat' # matlab\n",
    "save_path = f\"{vid_root}{save_file}\""
   ],
   "id": "bf60c241",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:/Sherry/poseTrackingXL/calibration_files/all_opt_arrays/102324_negated_camParams\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:29:52.799216Z",
     "start_time": "2025-03-11T03:29:52.340033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# models\n",
    "comNet = \"Z:/Sherry/poseTrackingXL/training_files/SLP/models/010725_com250107_235615.single_instance.n=460\" \n",
    "postureNet = \"Z:/Sherry/poseTrackingXL/training_files/SLP/models/010825_postureNet250108_164045.single_instance.n=460\"\n",
    "faceNet = \"C:/Users/xl313/OneDrive/Documents/GitHub/bird_pose_tracking/faceNet/j4-xl-v1.h5\"\n",
    "# if running face model, otherwise set to None\n",
    "joint_model = tf_load(faceNet, custom_objects={'tf': tf}, compile=True) # load the complete model\n",
    "jp_layer = [l for l in joint_model.layers if l.name == 'joint_pred'][0] # extract out \"joint_pred\" layer from the model \n",
    "face_model = tf.keras.Model(inputs=joint_model.input, outputs=jp_layer.output) # a new model that only output the \"joint_pred\" layer\n",
    "# face_model = None"
   ],
   "id": "a2e31d02",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:30:02.677267Z",
     "start_time": "2025-03-11T03:29:57.498347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the video reader for each camera\n",
    "all_readers = []\n",
    "for i in range(len(cam_ids)):\n",
    "    cam = cam_ids[i]\n",
    "    print(cam)\n",
    "    camPath = f\"{vid_root}{cam}.avi\"\n",
    "    # define the video reader obj and settings\n",
    "    api_id = cv2.CAP_FFMPEG\n",
    "    reader = cv2.VideoCapture(camPath, api_id)\n",
    "    if start_frame > 0:\n",
    "        reader.set(cv2.CAP_PROP_FRAME_COUNT, start_frame)\n",
    "    all_readers.append(reader)"
   ],
   "id": "6ec1fbff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue_cam\n",
      "green_cam\n",
      "red_cam\n",
      "yellow_cam\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "''' track posture '''\n",
    "obj = posture_tracker(all_readers, cam_params,\n",
    "                        com_model=comNet,\n",
    "                        posture_model=postureNet,\n",
    "                        face_model=face_model)\n",
    "results = obj.track_video(start_frame=start_frame,\n",
    "                            nFrames=nFrames)"
   ],
   "id": "87692c79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "''' save file '''\n",
    "# for python\n",
    "save_dict = {\"results\": results,\n",
    "            \"camNames\": cam_ids,\n",
    "            \"session\": vid_root,\n",
    "            \"start_frame\": start_frame,\n",
    "            \"n_frames\": nFrames,\n",
    "            \"cam_params\": cam_params\n",
    "}\n",
    "np.save(save_path, save_dict)"
   ],
   "id": "a209faa5850781fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a30042ba",
   "metadata": {},
   "source": [
    "# for matlab \n",
    "scipy.io.savemat(save_path,{\"posture_preds\": results['posture_preds'], \"posture_reproj\": results['posture_rep_err'],\n",
    "                     \"posture_rawpreds\": results['posture_rawpred'], \"com_preds\": results['com_preds'], \"com_reproj\": results['com_rep_err'],\n",
    "                     \"posture_conf\":results['posture_conf'], \"com_conf\":results['com_conf'], #  \"face_preds\":results['face_preds'], \"startTime\": startTime,\n",
    "                     \"camNames\": cam_ids, \"session\": vid_root, \"nFrames\": nFrames,\n",
    "                     \"camParams\": cam_params, }) # \"rawPostures\":sleap_raw_predicted_points_scale_back"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
