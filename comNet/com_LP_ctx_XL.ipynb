{
 "cells": [
  {
   "cell_type": "code",
   "id": "90564075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:41:20.648305Z",
     "start_time": "2024-11-10T21:41:20.018084Z"
    }
   },
   "source": [
    "\"\"\"\n",
    " a SLP project using labeled frames from Label3D - com_net model\n",
    "----------------------------------------------------\n",
    "**This notebook takes labeled training data from Label3D and packages it into a SLP project to train the com_net model on the coarse bird location (head, body, tail).**\n",
    "\n",
    "Reformat 3D points from Label3D into an array of 2D points\n",
    "Then, pass through `create_slp_project()` to make the SLP project file.\n",
    "\n",
    "The coarse predictions are then used to crop around the bird (posture net) and the head (face net) to predict the detaied keypoints and seed presence, respectively, on cropped video frames.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "import mat73\n",
    "import scipy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "10254771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:41:23.546050Z",
     "start_time": "2024-11-10T21:41:20.652014Z"
    }
   },
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/utils\")\n",
    "from slp_utils import create_slp_project, resize_and_pad_rows\n",
    "sys.path.append(\"../camera_calibration/\")\n",
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/pySBA\")\n",
    "import pySBA"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0ddce916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:42:32.401405Z",
     "start_time": "2024-11-10T21:42:32.385765Z"
    }
   },
   "source": [
    "''' Locate directories: UPDATE AS-APPROPRIATE '''\n",
    "proj_date = \"103124\"\n",
    "# for downsampling\n",
    "ds_fac = 4\n",
    "# skeleton file (nodes and edges)\n",
    "skeleton_file = 'C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/comNet/com_skeleton_IL.csv'\n",
    "# to save SLP project\n",
    "slp_project_dir = 'C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/training_files/SLP/'\n",
    "slp_project_file = f'{proj_date}_com_net.slp'\n",
    "slp_project_path = f'{slp_project_dir}{slp_project_file}'\n",
    "# location where trained images will be stored\n",
    "training_vid_dir = \"Z:/Sherry/poseTrackingXL/training_files/com_vids/\"\n",
    "vid_file = f'{proj_date}_com_vid.npy'\n",
    "training_vid_path = f'{training_vid_dir}{vid_file}'\n",
    "# Label3D training data\n",
    "training_dir = 'Z:/Sherry/poseTrackingXL/training_files/Label3D/'\n",
    "training_files = []\n",
    "for f in os.listdir(training_dir):\n",
    "    if 'videos' in f:\n",
    "        training_files.append(f)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:42:44.071722Z",
     "start_time": "2024-11-10T21:42:44.058628Z"
    }
   },
   "cell_type": "code",
   "source": "training_files",
   "id": "693ca90732649277",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMB155_100424_02_25_500_videos_LPctx.mat',\n",
       " 'AMB155_100424_2_5_500_videos.mat',\n",
       " 'ROS103_090324_10_800_videos_LPctx.mat',\n",
       " 'ROS103_092324_2_800_videos.mat',\n",
       " 'ROS103_092324_5_500_videos.mat',\n",
       " 'ROS103_092324_5_700_videos.mat',\n",
       " 'ROS103_092324_8_400_videos.mat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "bb697e94",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-11-10T21:41:25.758791Z",
     "start_time": "2024-11-10T21:41:25.745775Z"
    }
   },
   "source": [
    "''' Functions '''\n",
    "def avgBodyParts(data3D):\n",
    "    \"\"\"\n",
    "    averages across the labeled points for each coarse region:\n",
    "    - head: left eye, right eye (7, 11)\n",
    "    - body: center back, base tail, left wing, right wing (4, 5, 8, 12)\n",
    "    - tail: tip tail (6)\n",
    "    \"\"\"\n",
    "    headInd = [7, 11] \n",
    "    bodyInd = [4, 5, 8, 12]\n",
    "    tailInd = [6]\n",
    "    nFrames = data3D.shape[0]\n",
    "    nParts = data3D.shape[1]//3\n",
    "    data3D = np.reshape(data3D, (nFrames, nParts, 3))\n",
    "    headPts = np.mean(data3D[:, headInd], axis=1)\n",
    "    bodyPts = np.mean(data3D[:, bodyInd], axis=1)\n",
    "    tailPts = np.mean(data3D[:, tailInd], axis=1)\n",
    "    return (headPts, bodyPts, tailPts)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "64cba3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:42:10.882670Z",
     "start_time": "2024-11-10T21:42:10.871150Z"
    }
   },
   "source": [
    "def projectData(matfile):\n",
    "    '''\n",
    "    the purpose of this is to reproject 3D points onto 2D camera views again\n",
    "    takes in a matfile from Label3D which contains\n",
    "    - camera params\n",
    "    - 3D point locations\n",
    "    reshapes 3D data to (n_frames, n_nodes, 3)\n",
    "    - averages across head, body, and tail regions\n",
    "    reprojects onto each camera view to get an array of shape (n_frames, n_cams, n_nodes, 2) \n",
    "    '''\n",
    "    camParams = pySBA.convertParams(matfile['camParams'])\n",
    "    pt3d = avgBodyParts(matfile['data_3D'])\n",
    "    sba = pySBA.PySBA(camParams, np.NaN, np.NaN, np.NaN, np.NaN) #points_2d[:, :2], camera_ind, point_2dind3d, points_2d[:, 2])\n",
    "    nFrames = pt3d[0].shape[0]\n",
    "    nParts = len(pt3d)\n",
    "    nCams = camParams.shape[0]\n",
    "    allLabels = np.full((nFrames, nCams, nParts, 2), np.NaN)\n",
    "    for nCam in range(nCams):\n",
    "        for nPart in range(nParts):\n",
    "            allLabels[:, nCam, nPart, :] = sba.project(pt3d[nPart], np.tile(camParams[nCam],(nFrames,1))) # this convert 3d points to 2d by projecting onto images\n",
    "\n",
    "    return allLabels"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "22b3d05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:42:13.627240Z",
     "start_time": "2024-11-10T21:42:12.683220Z"
    }
   },
   "source": [
    "''' Get coarse 3D points and reformat into an array of 2D points '''\n",
    "# get the 2D points and frames for each Label3D file\n",
    "all_labels = [] # (n_frames, n_cams, n_nodes, 2)\n",
    "all_images = [] # CHECK SHAPE\n",
    "for fn in training_files:\n",
    "    print(fn)\n",
    "    file_path = f\"{training_dir}{fn}\"\n",
    "    matfile = mat73.loadmat(file_path)\n",
    "    labels = projectData(matfile)\n",
    "    images = []\n",
    "    for data in matfile['videos']:\n",
    "        images.append(data[0])\n",
    "    all_labels.append(labels)\n",
    "    all_images.append(images)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMB155_100424_02_25_500_videos_LPctx.mat\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'videos'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1547880\\2508928137.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprojectData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmatfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmatfile\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'videos'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m         \u001B[0mimages\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mall_labels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'videos'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_label =np.concatenate(all_labels, axis=0) # got rid of the 1 on first dimension\n",
    "print(np.shape(test_label))"
   ],
   "id": "62d472861f2cdb49",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f748c4d1",
   "metadata": {},
   "source": [
    "# reformat\n",
    "all_labels = np.concatenate(all_labels, axis=0) # got rid of the 1 on first dimension\n",
    "n_cams = all_labels.shape[1] # 4 cameras \n",
    "all_cams = [] # list (len (n_cams,)) of arrays (w, h, n_frames)\n",
    "for c in range(n_cams):\n",
    "    these_images = np.concatenate([i[c] for i in all_images], axis=3)\n",
    "    all_cams.append(np.squeeze(these_images))\n",
    "    \n",
    "#del all_images"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d2bbbf9d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# define the downsampled image size\n",
    "im_w = all_cams[0].shape[0]\n",
    "im_h = all_cams[0].shape[1]\n",
    "ds_size = (im_w//ds_fac, im_h//ds_fac) # pixels - need to adjust"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a8f64e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "''' plot a frame to check output '''\n",
    "ex_frame = 1\n",
    "# fig params\n",
    "f, ax = plt.subplots(n_cams//2, 2)\n",
    "colors = ['xkcd:scarlet', 'xkcd:cobalt blue', 'xkcd:saffron']\n",
    "# plot for each camera\n",
    "for n_cam in range(n_cams):\n",
    "    # get subplot index\n",
    "    if n_cam < n_cams//2:\n",
    "        r = n_cam\n",
    "        c = 0\n",
    "    else:\n",
    "        r = n_cam - n_cams//2\n",
    "        c = 1\n",
    "    # label keypoints\n",
    "    ax[r, c].imshow(images[n_cam][:, :, :, ex_frame]) # \n",
    "    ax[r, c].scatter(labels[ex_frame, n_cam, :, 0], \n",
    "                     labels[ex_frame, n_cam, :, 1],\n",
    "                     c=colors, marker='*', s=15)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23c42647",
   "metadata": {},
   "source": [
    "''' concatenate across camera views and downsample '''\n",
    "label_data = [] # shape (total_frames, n_nodes, 2) # nodes are  the average body parts (head, body, tail)\n",
    "image_data = [] # shape (total_frames, ds_h, ds_w, RGB) from (ds_w,ds_h,RGB,total_frames)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45cf429b",
   "metadata": {},
   "source": [
    "for n_cam in range(n_cams):\n",
    "    images = np.transpose(all_cams[n_cam], axes=[3,1,0,2]) \n",
    "    labels = all_labels[:, n_cam]\n",
    "    n_frames = labels.shape[0]\n",
    "    for f in range(n_frames):\n",
    "        #if np.isfinite(labels[f].sum()):\n",
    "        ds_ann = labels[f] / ds_fac\n",
    "        ds_im = cv2.resize(images[f], ds_size,\n",
    "                            interpolation=cv2.INTER_AREA)\n",
    "        label_data.append(ds_ann)\n",
    "        image_data.append(ds_im)\n",
    "label_data = np.stack(label_data, axis=0)\n",
    "image_data = np.stack(image_data, axis = 0)\n",
    "image_data = np.transpose(image_data,(0,2,1,3))\n",
    "#label_data = np.asarray(label_data)\n",
    "#image_data = np.asarray(image_data)\n",
    "np.save(training_vid_path, image_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.shape(image_data)",
   "id": "254ec8ee439fe9d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(image_data[1])",
   "id": "dc6078798cb84cc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00cc447c",
   "metadata": {},
   "source": [
    "# convert into a SLP project file\n",
    "create_slp_project(vid_path=training_vid_path, \n",
    "                   skeleton_file=skeleton_file,\n",
    "                   keypoints=label_data,\n",
    "                   slp_labels_file=slp_project_path)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
