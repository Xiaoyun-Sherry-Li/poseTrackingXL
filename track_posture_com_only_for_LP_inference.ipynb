{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:25:01.640560Z",
     "start_time": "2024-12-19T21:24:58.187950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "# from tensorflow.keras.models import load_model as tf_load\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/utils\")\n",
    "from load_matlab_data import loadmat_sbx\n",
    "from slp_utils import posture_tracker\n",
    "import scipy.io\n",
    "from slp_utils import create_slp_project, crop_from_com"
   ],
   "id": "1ede65d5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "cfc46d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:03:58.954938Z",
     "start_time": "2024-12-19T22:03:58.938926Z"
    }
   },
   "source": [
    "''' UPDATE data params as appropriate'''\n",
    "# cam params\n",
    "cam_ids = ['blue_cam', 'green_cam', 'red_cam', 'yellow_cam'] # check the input order\n",
    "im_w = 2200\n",
    "im_h = 650\n",
    "# video params\n",
    "start_frame = 185 * 50  # in frames at 50fps # SHERRY: start at 0 min\n",
    "nFrames = 1000 # in frames at 50fps "
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "085acfbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:05:51.478137Z",
     "start_time": "2024-12-19T22:05:51.450036Z"
    }
   },
   "source": [
    "''' UPDATE paths as needed '''\n",
    "# videos\n",
    "root_dir = \"Z:/Sherry/poseTrackingXL/training_files/raw_acquisition_copy/\"\n",
    "vid_root = f\"{root_dir}AMB155_100424_2/\"\n",
    "# camera params\n",
    "cam_param_dir = \"Z:/Sherry/poseTrackingXL/training_files/Label3D/\"  \n",
    "cam_param_file = \"102324_negated_camParams.mat\" # UPDATE if-needed to match session\n",
    "cam_params = loadmat_sbx(\"Z:/Sherry/poseTrackingXL/training_files/Label3D/102324_negated_camParams\")['camParams_negateR'] #['camParams']"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:/Sherry/poseTrackingXL/training_files/Label3D/102324_negated_camParams\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "447f641f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:05:58.141667Z",
     "start_time": "2024-12-19T22:05:58.110013Z"
    }
   },
   "source": [
    "# models\n",
    "comNet = \"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/training_files/SLP/models/101724_AMB155_comNet241017_211033.single_instance.n=100\" \n",
    "postureNet = \"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/training_files/SLP/models/101724_AMB155_postureNet241017_220555.single_instance.n=100\"\n",
    "# faceNet = \"Z:\\Selmaan\\DPK-transfer\\j4-v4\""
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "bf60c241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:06:01.090214Z",
     "start_time": "2024-12-19T22:06:01.084206Z"
    }
   },
   "source": [
    "# to save\n",
    "pred_date = \"121924\"\n",
    "# save_file = f'{pred_date}_posture_2stage.npy' # python\n",
    "save_file = f'{pred_date}_posture_2stage.mat' # matlab\n",
    "save_path = f\"{vid_root}{save_file}\""
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e433f3c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:06:03.114737Z",
     "start_time": "2024-12-19T22:06:03.083005Z"
    }
   },
   "source": [
    "''' set up for this run '''\n",
    "# set up GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "6ec1fbff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:06:17.087651Z",
     "start_time": "2024-12-19T22:06:15.340763Z"
    }
   },
   "source": [
    "# define the video reader for each camera\n",
    "all_readers = []\n",
    "for i in range(len(cam_ids)):\n",
    "    cam = cam_ids[i]\n",
    "    print(cam)\n",
    "    camPath = f\"{vid_root}{cam}.avi\"\n",
    "\n",
    "    # define the video reader obj and settings\n",
    "    api_id = cv2.CAP_FFMPEG\n",
    "    reader = cv2.VideoCapture(camPath, api_id)\n",
    "    if start_frame > 0:\n",
    "        reader.set(cv2.CAP_PROP_FRAME_COUNT, start_frame)\n",
    "    all_readers.append(reader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue_cam\n",
      "green_cam\n",
      "red_cam\n",
      "yellow_cam\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:06:20.252959Z",
     "start_time": "2024-12-19T22:06:20.237329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if running face model, otherwise set to None\n",
    "# face_model = tf_load(faceNet, custom_objects={'tf': tf})\n",
    "face_model = None"
   ],
   "id": "a2e31d02",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "87692c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T22:16:52.584341Z",
     "start_time": "2024-12-19T22:09:55.684233Z"
    }
   },
   "source": [
    "''' track posture '''\n",
    "obj = posture_tracker(all_readers, cam_params,\n",
    "                        com_model=comNet,\n",
    "                        posture_model=postureNet,\n",
    "                        face_model=face_model)\n",
    "results = obj.track_video_com(base_dir = \"Z:/Sherry/poseTrackingXL/training_files/posture_vids/AMB155_2_unseen_images\", start_frame=start_frame,\n",
    "                            nFrames=nFrames)\n",
    "# results = obj.track_video_com(start_frame=start_frame,\n",
    "#                                 nFrames=nFrames)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Camera Parameters\n",
      "cameraMats:  [array([[ 2.41702718e+03, -1.58864212e+02,  6.21403613e-01],\n",
      "       [-7.25358959e+02, -1.94132218e+02,  7.01161060e-01],\n",
      "       [-3.85120771e+02, -2.35069008e+03, -3.49615100e-01],\n",
      "       [ 8.78300401e+05,  1.94139233e+05,  8.01105665e+02]]), array([[-2.30149020e+03,  1.39717560e+02, -7.21147459e-01],\n",
      "       [ 1.05825604e+03,  1.78721097e+02, -6.07948470e-01],\n",
      "       [-3.30093947e+02, -2.35235430e+03, -3.32182180e-01],\n",
      "       [ 9.22424175e+05,  2.26582211e+05,  8.32531629e+02]]), array([[-7.72851025e+02, -1.00895733e+02,  7.05399101e-01],\n",
      "       [-2.44458657e+03,  9.66003973e+01, -6.37337998e-01],\n",
      "       [-3.51860470e+02, -2.40742776e+03, -3.10181213e-01],\n",
      "       [ 8.78909726e+05,  2.54698363e+05,  8.31167280e+02]]), array([[ 1.06196576e+03,  1.60508099e+02, -6.11385346e-01],\n",
      "       [ 2.31181050e+03, -2.02864429e+02,  7.18479141e-01],\n",
      "       [-3.86794424e+02, -2.35450657e+03, -3.31655970e-01],\n",
      "       [ 9.24258204e+05,  2.09566786e+05,  8.23582079e+02]])]\n",
      "Reading and Predicting\n",
      "Reading Frame 10000\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "AMB155_100424_2",
   "id": "271466d99ec723a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.shape(results[\"cropped_unseen_images\"])",
   "id": "2b72978a05f6bd22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.shape(crop_img)",
   "id": "b02b6e6513bad19b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(results[\"cropped_unseen_images\"][2,:,:,:])\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.show()"
   ],
   "id": "1e69368cccd8f386",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# to save the ds_img (cropped from comNet) to put it in Lightning Pose\n",
    "LP_cropped_images = results[\"cropped_unseen_images\"]\n",
    "np.shape(LP_cropped_images)\n",
    "from PIL import Image\n",
    "import os\n",
    "# Directory to save the temporary images\n",
    "output_dir = \"Z:/Sherry/poseTrackingXL/training_files/posture_vids/SLV_cache_unseen_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Convert each .npy to an image and save it\n",
    "for i, img_array in enumerate(LP_cropped_images):\n",
    "    img = Image.fromarray(img_array.astype(np.uint8))  # Convert to uint8 format for images\n",
    "    img.save(os.path.join(output_dir, f\"image_{i+1}.png\")) "
   ],
   "id": "9623cb0bac9382af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(np.shape(LP_cropped_images))",
   "id": "737049238cfb4851",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a10ccfe",
   "metadata": {},
   "source": [
    "''' save file '''\n",
    "# for python\n",
    "# save_dict = {\"results\": results,\n",
    "#             \"camNames\": cam_ids,\n",
    "#             \"session\": vid_root,\n",
    "#             \"start_frame\": start_frame,\n",
    "#             \"n_frames\": nFrames,\n",
    "#             \"cam_params\": cam_params\n",
    "# }\n",
    "# np.save(save_path, save_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a30042ba",
   "metadata": {},
   "source": [
    "# for matlab \n",
    "scipy.io.savemat(save_path,{\"posture_preds\": results['posture_preds'], \"posture_reproj\": results['posture_rep_err'],\n",
    "                     \"posture_rawpreds\": results['posture_rawpred'], \"com_preds\": results['com_preds'], \"com_reproj\": results['com_rep_err'],\n",
    "                     \"posture_conf\":results['posture_conf'], \"com_conf\":results['com_conf'], #  \"face_preds\":results['face_preds'], \"startTime\": startTime,\n",
    "                     \"camNames\": cam_ids, \"session\": vid_root, \"nFrames\": nFrames,\n",
    "                     \"camParams\": cam_params, }) # \"rawPostures\":sleap_raw_predicted_points_scale_back"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sys.path.append(\"C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/utils\")\n",
    "from slp_utils import create_slp_project, crop_from_com"
   ],
   "id": "c2f478ca80b267c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "slp_project_dir = 'C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/training_files/SLP/' # this is saved locally (at least temporaily instead of on locker)\n",
    "slp_project_file = f'102424_combined_net.slp'\n",
    "slp_project_path = f'{slp_project_dir}{slp_project_file}'\n",
    "skeleton_file = 'C:/Users/xl313/OneDrive/Documents/GitHub/poseTrackingXL/postureNet/posture_skeleton_IL.csv'\n",
    "\n",
    "training_vid_dir = 'Z:/Sherry/poseTrackingXL/training_files/'\n",
    "vid_file = f'102424_combined_pred_vid.npy'\n",
    "training_vid_path = f'{training_vid_dir}{vid_file}'\n",
    "np.save(training_vid_path, results['unseen_images'])"
   ],
   "id": "675a5a19ac01f0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# optional, create a sleap object to visualise inference results in sleap GUI.\n",
    "create_slp_project(vid_path=training_vid_path, \n",
    "                   skeleton_file=skeleton_file,\n",
    "                   keypoints=results['sleap_raw_predicted_points_scale_back'],\n",
    "                   slp_labels_file=slp_project_path)"
   ],
   "id": "fef7303e09d53535",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
