{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94302552",
   "metadata": {},
   "source": [
    "Create a SLP project using labeled frames from from Label3D - full model\n",
    "----------------------------------------------------\n",
    "**This notebook takes labeled training data from Label3D and packages it into a SLP project to train the full_net model.**\n",
    "\n",
    "Reformat 3D points from Label3D into an array of 2D points    \n",
    "- takes in a matfile from Label3D\n",
    "- reshapes to (n_frames, n_nodes, 3)\n",
    "- reprojects onto each camera view to get an array of shape (n_frames, n_cams, n_nodes, 2)\n",
    "    \n",
    "Then, pass through `create_slp_project()` to make the SLP project file.\n",
    "\n",
    "These data should be used with the **top-down** SLP strategy. With this method, SLP first finds the bird in downsampled video frames and crops around it. Then, it learns the detailed keypoint locations in these cropped, full-resolution video frames. This is a built-in method that seems to closely match Selmaan's com_net + posture_net approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a35c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import mat73\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "sys.path.append(\"../camera_calibration/\")\n",
    "import pySBA\n",
    "# from load_matlab_data import loadmat_sbx, _check_keys\n",
    "# from slp_utils import create_slp_project\n",
    "\n",
    "# from fullCreateDataset import projectData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52d37b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' set paths '''\n",
    "skeleton_file = './/full_skeleton_IL.csv'\n",
    "\n",
    "# to save SLP project\n",
    "slp_labels_file = '..//training_files/SLP/'\n",
    "\n",
    "# Label3D training data\n",
    "training_dir = '..//training_files/Label3D/'\n",
    "training_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2379cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get file names from a shared directory\n",
    "for f in os.listdir(training_dir):\n",
    "    training_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53bb1447-7341-4cda-b93c-2817517e0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Functions '''\n",
    "def formatData(data3D):\n",
    "    nFrames = data3D.shape[0]\n",
    "    nParts = data3D.shape[1]//3\n",
    "    data3D = np.reshape(data3D, (nFrames, nParts, 3))\n",
    "    return (data3D, nFrames, nParts)\n",
    "\n",
    "def projectData(matfile):\n",
    "    camParams = pySBA.convertParams(matfile['camParams'])\n",
    "    (pt3d, nFrames, nParts) = formatData(matfile['data_3D'])\n",
    "    sba = pySBA.PySBA(camParams, np.NaN, np.NaN, np.NaN, np.NaN) #points_2d[:, :2], camera_ind, point_2dind3d, points_2d[:, 2])\n",
    "    nCams = camParams.shape[0]\n",
    "    allLabels = np.full((nFrames, nCams, nParts, 2), np.NaN)\n",
    "    for nCam in range(nCams):\n",
    "        for nPart in range(nParts):\n",
    "            allLabels[:, nCam, nPart, :] = sba.project(pt3d[:,nPart], np.tile(camParams[nCam],(nFrames,1)))\n",
    "\n",
    "    return allLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5315eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240826_172822_Label3D_videos.mat\n"
     ]
    }
   ],
   "source": [
    "''' Get 3D points and reformat into an array of 2D points '''\n",
    "# get the 2D points and frames for each Label3D file\n",
    "all_labels = [] # (n_frames, n_cams, n_nodes, 2)\n",
    "all_images = [] \n",
    "for fn in training_files:\n",
    "    print(fn)\n",
    "    file_path = f\"{training_dir}{fn}\"\n",
    "    matfile = mat73.loadmat(file_path)\n",
    "    labels = projectData(matfile)\n",
    "    images = []\n",
    "    for data in matfile['videos']:\n",
    "        images.append(data[0])\n",
    "    all_labels.append(labels)\n",
    "    all_images.append(images)\n",
    "    \n",
    "# reformat\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "n_cams = all_labels.shape[1]\n",
    "all_cams = [] # list (len (n_cams,)) of arrays (w, h, n_frames)\n",
    "for c in range(n_cams):\n",
    "    these_images = np.concatenate([i[c] for i in all_images], axis=2)\n",
    "    all_cams.append(np.squeeze(these_images))\n",
    "del all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a frame to check output\n",
    "ex_frame = 50\n",
    "\n",
    "# fig params\n",
    "f, ax = plt.subplots(n_cams//2, 2)\n",
    "colors = ['xkcd:scarlet', 'xkcd:cobalt blue', 'xkcd:saffron']\n",
    "node_idx = np.asarray([0, 4, 14]) # topBeak, centerBack, rightFoot - could change\n",
    "x_idx = np.full(node_idx.shape[0], 0)\n",
    "y_idx = np.full(node_idx.shape[0], 1)\n",
    "\n",
    "# plot for each camera\n",
    "for n_cam in range(n_cams):\n",
    "    # get subplot index\n",
    "    if n_cam < n_cams//2:\n",
    "        r = n_cam\n",
    "        c = 0\n",
    "    else:\n",
    "        r = n_cam - n_cams//2\n",
    "        c = 1\n",
    "    \n",
    "    # label keypoints\n",
    "    ax[r, c].imshow(images[n_cam][:, :, ex_frame], cmap='gray')\n",
    "    ax[r, c].scatter(labels[ex_frame, n_cam, :, x_idx], \n",
    "                     labels[ex_frame, n_cam, :, y_idx]\n",
    "                     c=colors, marker='*', s=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de9f161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' concatenate across camera views to pass into SLP '''\n",
    "label_data = [] # shape (total_frames, n_nodes, 2)\n",
    "image_data = [] # shape (total_frames, ds_w, ds_h)\n",
    "\n",
    "for n_cam in range(n_cams):\n",
    "    images = np.transpose(all_cams[n_cam], axes=[2, 0, 1]) \n",
    "    labels = all_labels[:, n_cam]\n",
    "    n_frames = labels.shape[0]\n",
    "    for f in range(n_frames):\n",
    "        if np.isfinite(labels[f].sum()):\n",
    "            label_data.append(labels[f])\n",
    "            image_data.append(images[f])\n",
    "label_data = np.asarray(label_data)\n",
    "image_data = np.asarray(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0730f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_slp_project(images=image_data, \n",
    "                   skeleton_file=skeleton_file,\n",
    "                   keypoints=label_data,\n",
    "                   slp_labels_file=slp_labels_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
