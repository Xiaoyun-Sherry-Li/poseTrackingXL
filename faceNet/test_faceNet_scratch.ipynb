{
 "cells": [
  {
   "cell_type": "code",
   "id": "304c651b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T00:02:22.099653Z",
     "start_time": "2025-01-13T00:02:22.083633Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "#from testFaceNet import example_idx\n",
    "\n",
    "sys.path.append(\"..//utils/\")\n",
    "# from slp_utils import crop_from_com\n",
    "from triangulation_utils import unDistortPoints, camera_matrix, triangulate_confThresh_lowestErr\n",
    "sys.path.append(\"..//camera_calibration/\")\n",
    "import pySBA\n",
    "import mat73"
   ],
   "outputs": [],
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "id": "d5a52d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T22:07:32.604108Z",
     "start_time": "2025-01-12T22:07:32.598604Z"
    }
   },
   "source": [
    "''' cropping params '''\n",
    "face_w3d=0.06 # scaling factor\n",
    "face_crop_size=(128,128) # pixels\n",
    "head_idx=np.asarray([7, 11])\n",
    "\n",
    "''' set paths '''\n",
    "# proj_date = input(\"input today's date (YYMMDD): \")\n",
    "skeleton_file = './/posture_skeleton_IL.csv'\n",
    "faceNet = \"j4-xl-v1.h5\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:53:59.358056Z",
     "start_time": "2025-01-12T23:53:59.342043Z"
    }
   },
   "cell_type": "code",
   "source": "pwd",
   "id": "604502bdd7dc3aea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\xl313\\\\OneDrive\\\\Documents\\\\GitHub\\\\bird_pose_tracking\\\\faceNet'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "id": "d8d02890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:11.122430Z",
     "start_time": "2025-01-12T23:46:11.095599Z"
    }
   },
   "source": [
    "''' load the training images and faceNet model '''\n",
    "# Label3D training data\n",
    "training_dir = '..//training_files/Label3D/'\n",
    "training_files = []\n",
    "for f in os.listdir(training_dir):\n",
    "    if 'seed' in f:\n",
    "        training_files.append(f) # there is one examplar training video file\n",
    "training_files"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seed_no_seed_vid.mat']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "id": "d427f9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:12.772413Z",
     "start_time": "2025-01-12T23:46:12.756702Z"
    }
   },
   "source": [
    "def crop_from_com(img, centroid, half_width, crop_size = (320,320)):\n",
    "    '''\n",
    "    Crops an image around a given centroid (crop dims defined by half_width)\n",
    "    and resizes to the specified crop_size.\n",
    "    '''\n",
    "    ctr = np.round(centroid).astype(int)\n",
    "    half_width = np.round(half_width).astype(int)\n",
    "    img_h, img_w = img.shape\n",
    "    \n",
    "    xmin = np.min([np.max([ctr[0] - half_width, 0]), img_w - 1])\n",
    "    xmax = np.max([np.min([ctr[0] + half_width + 1, img_w]), 1])\n",
    "    ymin = np.min([np.max([ctr[1] - half_width, 0]), img_h - 1])\n",
    "    ymax = np.max([np.min([ctr[1] + half_width + 1, img_h]), 1])\n",
    "    \n",
    "    crop_img = cv2.resize(img[ymin:ymax, xmin:xmax], crop_size, cv2.INTER_AREA)\n",
    "    min_ind = np.array([xmin, ymin])\n",
    "    max_ind = np.array([xmax, ymax])\n",
    "    crop_scale = crop_size / (max_ind - min_ind)\n",
    "    \n",
    "    return crop_img, min_ind, crop_scale"
   ],
   "outputs": [],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "id": "ca0d2831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:14.552533Z",
     "start_time": "2025-01-12T23:46:14.533867Z"
    }
   },
   "source": [
    "def formatData(data3D):\n",
    "    nFrames = data3D.shape[0]\n",
    "    nParts = data3D.shape[1]//3\n",
    "    data3D = np.reshape(data3D, (nFrames, nParts, 3))\n",
    "    return (data3D, nFrames, nParts)\n",
    "\n",
    "def get_crop_info(matfile):\n",
    "    # get the camera params for this file\n",
    "    camParams = pySBA.convertParams(matfile['camParams'])\n",
    "    nCams = camParams.shape[0]\n",
    "    pt3d, nFrames, nParts = formatData(matfile['data_3D'])\n",
    "    sba = pySBA.PySBA(camParams, np.NaN, np.NaN, np.NaN, np.NaN)\n",
    "        \n",
    "    # get the 3D distance from each camera for cropping scale\n",
    "    head_COM = np.nanmean(pt3d[:, head_idx], axis=1)\n",
    "    allCamScales = np.full((nFrames, nCams), np.NaN)\n",
    "    allCentroids = np.full((nFrames, nCams, 2), np.NaN)\n",
    "    for f in range(nFrames):\n",
    "        this_COM = head_COM[f]\n",
    "        allCentroids[f] = sba.project(np.tile(this_COM, (nCams, 1)), camParams)  # get reprojected centroid locations\n",
    "        camDist = sba.rotate(np.tile(this_COM, (nCams, 1)), camParams[:, :3])  # rotate to camera coordinates\n",
    "        camDist = camDist[:, 2] + camParams[:, 5]  # get z-axis distance ie along optical axis\n",
    "        allCamScales[f] = camParams[:, 6] / camDist  # convert to focal length divided by distance\n",
    "    \n",
    "    return allCamScales, allCentroids"
   ],
   "outputs": [],
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "id": "b53ab9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:16.591091Z",
     "start_time": "2025-01-12T23:46:16.366658Z"
    }
   },
   "source": [
    "''' Reformat 3D points from Label3D into an array of 2D points '''\n",
    "# get the camera views, head centroids, and camera scales for each Label3D file\n",
    "all_images = [] # list (len (n_cams,)) of arrays (w, h, n_frames)\n",
    "all_scales = [] # (n_frames, n_cams)\n",
    "all_centroids = [] # (n_frames, n_cams, 2)\n",
    "for fn in training_files:\n",
    "    print(fn)\n",
    "    file_path = f\"{training_dir}{fn}\"\n",
    "    matfile = mat73.loadmat(file_path)\n",
    "    scales, centroids = get_crop_info(matfile)\n",
    "    images = []\n",
    "    for data in matfile['videos']:\n",
    "        images.append(data[0])\n",
    "    print(f'n frames = {images[0].shape[-1]}')\n",
    "    all_images.append(images)\n",
    "    all_scales.append(scales)\n",
    "    all_centroids.append(centroids)\n",
    "    \n",
    "# reformat\n",
    "all_scales = np.concatenate(all_scales, axis=0)\n",
    "all_centroids = np.concatenate(all_centroids, axis=0)\n",
    "n_cams = all_scales.shape[1]\n",
    "all_cams = []\n",
    "for c in range(n_cams):\n",
    "    these_images = np.concatenate([i[c] for i in all_images], axis=3)\n",
    "    all_cams.append(np.squeeze(these_images))\n",
    "del all_images"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_no_seed_vid.mat\n",
      "n frames = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xl313\\anaconda3\\envs\\sleap\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "id": "00cfc5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:18.733631Z",
     "start_time": "2025-01-12T23:46:18.723615Z"
    }
   },
   "source": [
    "''' crop and resize frames '''\n",
    "n_frames = all_scales.shape[0]\n",
    "face_images = np.zeros([n_frames, face_crop_size[1], face_crop_size[0], n_cams], dtype='uint8') # shape (total_frames, ds_h, ds_w)\n",
    "for n_cam in range(n_cams):\n",
    "    images = np.transpose(all_cams[n_cam], axes=[2, 0, 1]) \n",
    "    scales = all_scales[:, n_cam]\n",
    "    centroids = all_centroids[:, n_cam]\n",
    "    for f in range(n_frames):\n",
    "        if np.isfinite(centroids[f].sum()):\n",
    "            full_image = images[f]\n",
    "            head_ctr = np.maximum(centroids[f], 0) # rough x-y head coords as in comNet\n",
    "            head_ctr[0] = np.min([head_ctr[0], full_image.shape[1]])\n",
    "            head_ctr[1] = np.min([head_ctr[1], full_image.shape[0]])\n",
    "            half_width = np.nanmax([np.round(face_w3d * scales[f]), 15]) # minimum 31px image for head\n",
    "            crop_img, _, _ = crop_from_com(full_image, head_ctr, half_width, face_crop_size)\n",
    "            face_images[f, :, :, n_cam] = crop_img"
   ],
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:20.909704Z",
     "start_time": "2025-01-12T23:46:20.894072Z"
    }
   },
   "cell_type": "code",
   "source": "np.shape(face_images)",
   "id": "eef331d4d4609ea1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 128, 128, 4)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "id": "1c7d049e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:46:22.068408Z",
     "start_time": "2025-01-12T23:46:22.052327Z"
    }
   },
   "source": [
    "# only keep frames where head is labeled in all views\n",
    "label_idx = []\n",
    "for f in range(n_frames):\n",
    "    if np.isfinite(np.sum(all_centroids[f])):\n",
    "        label_idx.append(f)\n",
    "face_images = face_images[np.asarray(label_idx)]\n",
    "n_labeled_frames = face_images.shape[0]"
   ],
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:48:10.804538Z",
     "start_time": "2025-01-12T23:48:10.788906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' predict seed/no seed - score only '''\n",
    "# define new network with view-specific weights and make predictions\n",
    "print('\\nreading and predicting...')\n",
    "jp_layer = [l for l in face_model.layers if l.name == 'joint_pred'][0]\n",
    "pred_model = tf.keras.Model(inputs=face_model.input, outputs=jp_layer.output)\n",
    "facePreds = []\n",
    "for face_img in face_images:\n",
    "    thisPrediction = pred_model.predict_on_batch(face_img[None, :, :, :])\n",
    "    facePreds.append(thisPrediction.copy())"
   ],
   "id": "f37d91c84b92f211",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading and predicting...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'face_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_191352\\50725047.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# define new network with view-specific weights and make predictions\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\nreading and predicting...'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mjp_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0ml\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mface_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'joint_pred'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mpred_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mface_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mjp_layer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mfacePreds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'face_model' is not defined"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "id": "d488c7c0-91e0-4763-8128-9f735df88cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T23:47:46.813508Z",
     "start_time": "2025-01-12T23:47:46.786373Z"
    }
   },
   "source": [
    "''' plot 10 frames to check output '''\n",
    "# example_idx = np.random.randint(n_labeled_frames, size=10)\n",
    "example_idx = np.array([12,13])\n",
    "    \n",
    "for ex in example_idx:\n",
    "    # get the weight and score\n",
    "    val = facePreds[ex]\n",
    "    score = np.squeeze(val)\n",
    "\n",
    "    # plot the face and label with score\n",
    "    f, ax = plt.subplots(2, 2, figsize=(4, 4))\n",
    "    ax[0, 0].imshow(face_images[ex, :, :, 0], cmap='gray')\n",
    "    ax[0, 1].imshow(face_images[ex, :, :, 1], cmap='gray')\n",
    "    ax[1, 0].imshow(face_images[ex, :, :, 2], cmap='gray')\n",
    "    ax[1, 1].imshow(face_images[ex, :, :, 3], cmap='gray')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "\n",
    "    # label with the score\n",
    "    f.suptitle(f'score = {score:.3f}')\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'facePreds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_191352\\763084370.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mex\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mexample_idx\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;31m# get the weight and score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfacePreds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0mscore\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'facePreds' is not defined"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851accd2-fe71-4164-9ccc-2da300bcb501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
